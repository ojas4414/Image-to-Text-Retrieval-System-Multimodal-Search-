{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch,sys,os\n",
        "print(\"Python: \",sys.version.split()[0])\n",
        "print(\"PyTorch: \",torch.__version__)\n",
        "print(\"CUDA: \",torch.cuda.is_available())\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_ROOT =\"/content/drive/MyDrive/cyberpunk_analyser\"\n",
        "os.makedirs(PROJECT_ROOT,exist_ok=True)\n",
        "os.makedirs(os.path.join(PROJECT_ROOT,\"data/images\"),exist_ok=True)\n",
        "os.makedirs(os.path.join(PROJECT_ROOT,\"indexs\"),exist_ok=True)\n",
        "print(\"Project root:\",PROJECT_ROOT)"
      ],
      "metadata": {
        "id": "0BCfHBCs4KSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvU6AMG0zt3T",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu streamlit==1.25.0 pillow pandas tqdm accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os,textwrap\n",
        "SRC_DIR= os.path.join(\"/content\",\"cyberpunk_src\")\n",
        "os.makedirs(SRC_DIR,exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "extractors = textwrap.dedent(\"\"\"\\\n",
        "    from transformers import BlipForConditionalGeneration, BlipProcessor, CLIPModel, CLIPProcessor\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # BLIP captioner (lightweight base)\n",
        "    blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(DEVICE)\n",
        "\n",
        "    # CLIP for image embeddings\n",
        "    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(DEVICE)\n",
        "    clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "    # Sentence Transformer for text embeddings\n",
        "    sbert = SentenceTransformer(\"all-MiniLM-L6-v2\", device=DEVICE)\n",
        "\n",
        "    def generate_caption_pil(img_pil, max_length=50):\n",
        "        inputs = blip_processor(images=img_pil, return_tensors=\"pt\").to(DEVICE)\n",
        "        out = blip_model.generate(**inputs, max_new_tokens=max_length)\n",
        "        caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "\n",
        "    def generate_caption(image_path, max_length=50):\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        return generate_caption_pil(img, max_length)\n",
        "\n",
        "    def image_embedding(image_path):\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        inputs = clip_processor(images=img, return_tensors=\"pt\").to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            emb = clip_model.get_image_features(**inputs)\n",
        "        emb = emb.cpu().numpy()[0].astype('float32')\n",
        "        norm = np.linalg.norm(emb) + 1e-10\n",
        "        return emb / norm\n",
        "\n",
        "    def text_embedding(text):\n",
        "        emb = sbert.encode(text, convert_to_numpy=True)\n",
        "        emb = emb.astype('float32')\n",
        "        norm = (np.linalg.norm(emb) + 1e-10)\n",
        "        return emb / norm\n",
        "\"\"\")\n",
        "open(os.path.join(SRC_DIR, \"extractors.py\"), \"w\").write(extractors)\n",
        "\n",
        "indexer = textwrap.dedent(\"\"\"\\\n",
        "    import faiss\n",
        "    import numpy as np\n",
        "    import pickle\n",
        "\n",
        "    class FaissIndex:\n",
        "        def __init__(self, dim):\n",
        "            self.dim = dim\n",
        "            self.index = faiss.IndexFlatIP(dim)  # inner product; use normalized vectors\n",
        "            self.id_map = []\n",
        "\n",
        "        def add(self, vectors, ids):\n",
        "            # vectors: (n, dim) numpy float32\n",
        "            self.index.add(vectors)\n",
        "            self.id_map.extend(ids)\n",
        "\n",
        "        def search(self, qvec, top_k=5):\n",
        "            qvec = qvec.reshape(1, -1).astype('float32')\n",
        "            scores, idxs = self.index.search(qvec, top_k)\n",
        "            results = []\n",
        "            for s, i in zip(scores[0], idxs[0]):\n",
        "                if i == -1:\n",
        "                    continue\n",
        "                results.append((self.id_map[i], float(s)))\n",
        "            return results\n",
        "\n",
        "        def save(self, base_path):\n",
        "            faiss.write_index(self.index, base_path + \".index\")\n",
        "            with open(base_path + \".meta.pkl\", \"wb\") as f:\n",
        "                pickle.dump(self.id_map, f)\n",
        "\n",
        "        def load(self, base_path):\n",
        "            self.index = faiss.read_index(base_path + \".index\")\n",
        "            with open(base_path + \".meta.pkl\", \"rb\") as f:\n",
        "                self.id_map = pickle.load(f)\n",
        "\"\"\")\n",
        "open(os.path.join(SRC_DIR, \"indexer.py\"), \"w\").write(indexer)\n",
        "\n",
        "\n",
        "rag = textwrap.dedent(\"\"\"\\\n",
        "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "    import torch\n",
        "\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model_name = \"google/flan-t5-small\"  # runs on Colab; small but useful\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    rag_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(DEVICE)\n",
        "\n",
        "    def generate_answer(retrieved_texts, user_question, max_length=128):\n",
        "        context = \"\\\\n\".join(retrieved_texts) if retrieved_texts else \"\"\n",
        "        prompt = f\"Context: {context}\\\\n\\\\nQuestion: {user_question}\\\\nAnswer concisely:\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            out = rag_model.generate(**inputs, max_new_tokens=max_length)\n",
        "        return tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\"\"\")\n",
        "open(os.path.join(SRC_DIR, \"rag.py\"), \"w\").write(rag)\n",
        "\n",
        "print(\"Wrote source files to\", SRC_DIR)\n"
      ],
      "metadata": {
        "id": "SnXy_uLiyM-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textwrap\n",
        "\n",
        "SRC_DIR = os.path.join(\"/content\", \"cyberpunk_src\")\n",
        "os.makedirs(SRC_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "rag_code = textwrap.dedent(\"\"\"\\\n",
        "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "    import torch\n",
        "\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model_name = \"google/flan-t5-small\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    rag_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(DEVICE)\n",
        "\n",
        "    def generate_answer(retrieved_texts, user_question, max_length=128):\n",
        "        # 1. Filter the list to ensure we only have strings\n",
        "        clean_texts = []\n",
        "        if isinstance(retrieved_texts, list):\n",
        "            for t in retrieved_texts:\n",
        "                # Only append if it is a string and not empty\n",
        "                if isinstance(t, str) and t.strip():\n",
        "                    clean_texts.append(t)\n",
        "\n",
        "        # 2. Handle case where no valid text was found\n",
        "        if not clean_texts:\n",
        "            context = \"\"\n",
        "        else:\n",
        "            context = \"\\\\n\".join(clean_texts)\n",
        "\n",
        "        # 3. Generate the answer\n",
        "        prompt = f\"Context: {context}\\\\n\\\\nQuestion: {user_question}\\\\nAnswer concisely:\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            out = rag_model.generate(**inputs, max_new_tokens=max_length)\n",
        "        return tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\"\"\")\n",
        "\n",
        "with open(os.path.join(SRC_DIR, \"rag.py\"), \"w\") as f:\n",
        "    f.write(rag_code)\n",
        "\n",
        "print(\"SUCCESS: rag.py rewritten with type-checking safety.\")"
      ],
      "metadata": {
        "id": "nEN0DcnjLPTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 /content/cyberpunk_src/rag.py\n"
      ],
      "metadata": {
        "id": "O5-MLWcA-Eri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd, os\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/cyberpunk_analyser\"\n",
        "meta_path = os.path.join(PROJECT_ROOT, \"data_metadata_template.csv\")\n",
        "sample = pd.DataFrame([\n",
        "    {\"id\":\"img_001\",\"filename\":\"img_001.jpg\",\"caption\":\"city neon alley with a holographic sign\",\"tags\":\"city,neon,holo,alley\",\"description\":\"A rainy neon alley with a lone courier and holographic signboards.\"},\n",
        "    {\"id\":\"img_002\",\"filename\":\"img_002.jpg\",\"caption\":\"cybernetic arm holding a compact drone\",\"tags\":\"cyber-arm,drone,gadget\",\"description\":\"Close-up of a cybernetic forearm holding a small reconnaissance drone.\"},\n",
        "    {\"id\":\"img_003\",\"filename\":\"img_003.jpg\",\"caption\":\"street vendor under neon umbrella\",\"tags\":\"vendor,street,neon\",\"description\":\"A street food vendor with bright neon lighting and holographic menu.\"},\n",
        "    {\"id\":\"img_004\",\"filename\":\"img_004.jpg\",\"caption\":\"armored figure with energy blade\",\"tags\":\"armor,blade,weapon\",\"description\":\"A combat-ready figure wearing reinforced armor and an energy blade on hip.\"},\n",
        "    {\"id\":\"img_005\",\"filename\":\"img_005.jpg\",\"caption\":\"holo-terminal and floating UI panels\",\"tags\":\"ui,hologram,terminal\",\"description\":\"Holographic terminal projecting floating user interface panels in a dim room.\"},\n",
        "    {\"id\":\"img_006\",\"filename\":\"img_006.jpg\"},\n",
        "    {\"id\":\"img_007\",\"filename\":\"img_007.jpg\"},\n",
        "\n",
        "])\n",
        "sample.to_csv(os.path.join(PROJECT_ROOT, \"metadata.csv\"), index=False)\n",
        "print(\"Wrote metadata template to\", os.path.join(PROJECT_ROOT, \"metadata.csv\"))\n",
        "print(\"Now upload corresponding image files into:\", os.path.join(PROJECT_ROOT, \"data\",\"images\"))\n"
      ],
      "metadata": {
        "id": "jhIUwELQyQc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/cyberpunk_analyser\"\n",
        "SRC_DIR = \"/content/cyberpunk_src\"\n",
        "\n",
        "sys.path.append(SRC_DIR)\n",
        "\n",
        "\n",
        "from extractors import image_embedding, text_embedding, generate_caption\n",
        "from indexer import FaissIndex\n",
        "\n",
        "\n",
        "meta_path = os.path.join(PROJECT_ROOT, \"metadata.csv\")\n",
        "meta = pd.read_csv(meta_path)\n",
        "\n",
        "\n",
        "image_vecs = []\n",
        "image_ids  = []\n",
        "text_vecs  = []\n",
        "text_ids   = []\n",
        "\n",
        "\n",
        "for idx, row in meta.iterrows():\n",
        "    img_path = os.path.join(\n",
        "    PROJECT_ROOT,\n",
        "    \"data_metadata_template.csv\",\n",
        "    row[\"filename\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(\"Missing\", img_path, \"- skipping\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    img_emb = image_embedding(img_path)\n",
        "    image_vecs.append(img_emb)\n",
        "    image_ids.append(row[\"id\"])\n",
        "\n",
        "\n",
        "    desc = row.get(\"description\")\n",
        "    cap  = row.get(\"caption\")\n",
        "\n",
        "    if pd.notna(desc) and isinstance(desc, str) and desc.strip():\n",
        "        text = desc\n",
        "    elif pd.notna(cap) and isinstance(cap, str) and cap.strip():\n",
        "        text = cap\n",
        "    else:\n",
        "\n",
        "        print(f\"Using BLIP for {row['id']}\")\n",
        "        text = generate_caption(img_path)\n",
        "\n",
        "\n",
        "    txt_emb = text_embedding(text)\n",
        "    text_vecs.append(txt_emb)\n",
        "    text_ids.append(row[\"id\"])\n",
        "\n",
        "\n",
        "if len(image_vecs) > 0:\n",
        "    image_vecs = np.vstack(image_vecs).astype(\"float32\")\n",
        "    text_vecs  = np.vstack(text_vecs).astype(\"float32\")\n",
        "\n",
        "\n",
        "    img_dim = image_vecs.shape[1]\n",
        "    img_index = FaissIndex(img_dim)\n",
        "    img_index.add(image_vecs, image_ids)\n",
        "    img_index.save(os.path.join(PROJECT_ROOT, \"indexes\", \"image_index\"))\n",
        "\n",
        "\n",
        "    txt_dim = text_vecs.shape[1]\n",
        "    txt_index = FaissIndex(txt_dim)\n",
        "    txt_index.add(text_vecs, text_ids)\n",
        "    txt_index.save(os.path.join(PROJECT_ROOT, \"indexes\", \"text_index\"))\n",
        "\n",
        "    print(\"Indexes built and saved to Drive.\")\n",
        "\n",
        "else:\n",
        "    print(\"No images were indexed. Upload images and re-run.\")\n"
      ],
      "metadata": {
        "id": "BTLhPIPhyQvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/cyberpunk_analyser\"\n",
        "\n",
        "print(\"metadata exists:\", os.path.exists(os.path.join(PROJECT_ROOT, \"metadata.csv\")))\n",
        "print(\"images:\", os.listdir(os.path.join(PROJECT_ROOT, \"data\", \"images\")))\n",
        "print(\"indexes:\", os.listdir(os.path.join(PROJECT_ROOT, \"indexes\")))\n",
        "\n",
        "df = pd.read_csv(os.path.join(PROJECT_ROOT, \"metadata.csv\"))\n",
        "print(\"metadata rows:\", len(df))\n",
        "print(df[[\"id\", \"filename\"]])\n"
      ],
      "metadata": {
        "id": "aJ6Y2i37LDCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "id": "WfiYuHTWyQWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/cyberpunk_analyser/data_metadata_template\n"
      ],
      "metadata": {
        "id": "3miaBpLhtncF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/drive/MyDrive/cyberpunk_analyser\n"
      ],
      "metadata": {
        "id": "sArSIHFCtn9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INDEX_DIR = os.path.join(PROJECT_ROOT, \"indexes\")\n",
        "os.makedirs(INDEX_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "8HkcccxjtoWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from extractors import generate_caption, image_embedding, text_embedding\n",
        "from rag import generate_answer\n",
        "from indexer import FaissIndex\n",
        "\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/cyberpunk_analyser\"\n",
        "INDEX_DIR = os.path.join(PROJECT_ROOT, \"indexes\")\n",
        "META_PATH = os.path.join(PROJECT_ROOT, \"metadata.csv\")\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name in uploaded:\n",
        "    tmp_path = \"/content/\" + name\n",
        "    print(\"\\nUploaded:\", name)\n",
        "\n",
        "\n",
        "    caption = generate_caption(tmp_path)\n",
        "    print(\"BLIP Caption:\", caption)\n",
        "\n",
        "\n",
        "    img_emb = image_embedding(tmp_path)\n",
        "\n",
        "    img_idx = FaissIndex(img_emb.shape[0])\n",
        "    img_idx.load(os.path.join(INDEX_DIR, \"image_index\"))\n",
        "\n",
        "    sim_images = img_idx.search(img_emb, top_k=2)\n",
        "    print(\"Top similar images:\", sim_images)\n",
        "\n",
        "\n",
        "    cap_emb = text_embedding(caption)\n",
        "\n",
        "    text_idx = FaissIndex(cap_emb.shape[0])\n",
        "    text_idx.load(os.path.join(INDEX_DIR, \"text_index\"))\n",
        "\n",
        "    docs = text_idx.search(cap_emb, top_k=3)\n",
        "\n",
        "\n",
        "    meta = pd.read_csv(META_PATH)\n",
        "\n",
        "    retrieved_texts = []\n",
        "    for did, score in docs:\n",
        "        row = meta[meta[\"id\"] == did]\n",
        "        if not row.empty:\n",
        "            desc = row.iloc[0].get(\"description\")\n",
        "            cap  = row.iloc[0].get(\"caption\")\n",
        "            if pd.notna(desc):\n",
        "                retrieved_texts.append(desc)\n",
        "            elif pd.notna(cap):\n",
        "                retrieved_texts.append(cap)\n",
        "\n",
        "    print(\"Retrieved docs:\", retrieved_texts)\n",
        "\n",
        "\n",
        "    question = input(\n",
        "        \"\\nAsk a question about the image \"\n",
        "        \"(e.g. 'show similar images', 'describe the scene'): \"\n",
        "    ).strip().lower()\n",
        "\n",
        "\n",
        "    if \"similar\" in question and \"image\" in question:\n",
        "        print(\"\\nShowing similar images:\\n\")\n",
        "\n",
        "        fig, axes = plt.subplots(1, len(sim_images), figsize=(15, 5))\n",
        "\n",
        "\n",
        "        if len(sim_images) == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        for ax, (img_id, score) in zip(axes, sim_images):\n",
        "            row = meta[meta[\"id\"] == img_id]\n",
        "            if row.empty:\n",
        "                ax.axis(\"off\")\n",
        "                continue\n",
        "\n",
        "            filename = row.iloc[0][\"filename\"]\n",
        "            img_path = os.path.join(PROJECT_ROOT, \"data_metadata_template.csv\", filename)\n",
        "\n",
        "            if os.path.exists(img_path):\n",
        "                img = Image.open(img_path).convert(\"RGB\")\n",
        "                ax.imshow(img)\n",
        "                ax.set_title(f\"{img_id}\\nscore={score:.2f}\")\n",
        "                ax.axis(\"off\")\n",
        "            else:\n",
        "                ax.axis(\"off\")\n",
        "\n",
        "        plt.show()\n",
        "        continue\n",
        "\n",
        "\n",
        "    if question == \"\":\n",
        "        question = (\n",
        "            \"Describe the scene and mention any notable objects or technology if visible. \"\n",
        "            \"If nothing stands out, say so explicitly.\"\n",
        "        )\n",
        "\n",
        "\n",
        "    answer = generate_answer(retrieved_texts, question)\n",
        "\n",
        "    print(\"\\nQ:\", question)\n",
        "    print(\"A:\", answer)\n"
      ],
      "metadata": {
        "id": "v51tvcCs6NMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/cyberpunk_analyser/data_metadata_template.csv\"\n",
        "\n",
        "print(\"Exists:\", os.path.exists(path))\n",
        "print(\"Is directory:\", os.path.isdir(path))\n",
        "print(\"Is file:\", os.path.isfile(path))\n",
        "\n",
        "print(\"\\nContents:\")\n",
        "if os.path.isdir(path):\n",
        "    print(os.listdir(path))\n"
      ],
      "metadata": {
        "id": "qKmjOyKg9xJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pyngrok streamlit fastapi uvicorn nest-asyncio\n",
        "\n"
      ],
      "metadata": {
        "id": "k9v8RnBG-N6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /usr/local/bin/ngrok\n",
        "!wget -q https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-v3-stable-linux-amd64.zip\n",
        "!mv ngrok /usr/local/bin/ngrok\n",
        "!chmod +x /usr/local/bin/ngrok\n",
        "!ngrok version\n"
      ],
      "metadata": {
        "id": "MkiFMOraGcO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/streamlit_app.py\n",
        "import streamlit as st\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import streamlit.components.v1 as components\n",
        "\n",
        "\n",
        "st.set_page_config(\n",
        "    layout=\"wide\",\n",
        "    page_title=\"CYBERPUNK\"\n",
        ")\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "\n",
        "/* ===== MATRIX RAIN OVERLAY (FIXED & BLENDED) ===== */\n",
        ".matrix-layer {\n",
        "    position: fixed;\n",
        "    inset: 0;\n",
        "    pointer-events: none;\n",
        "    font-family: monospace;\n",
        "    font-size: 12px;\n",
        "    line-height: 14px;\n",
        "    letter-spacing: 10px;\n",
        "    white-space: pre-wrap;\n",
        "    z-index: -10;\n",
        "    text-shadow: 0 0 6px currentColor;\n",
        "}\n",
        "\n",
        "/* Cyan – main downward rain */\n",
        ".matrix-cyan {\n",
        "    color: rgba(0, 255, 255, 0.9);\n",
        "    animation: matrixDown 9s linear infinite;\n",
        "    opacity: 0.35;\n",
        "}\n",
        "\n",
        "/* Red – right side, upward */\n",
        ".matrix-red {\n",
        "    color: rgba(255, 40, 90, 0.85);\n",
        "    animation: matrixUp 13s linear infinite;\n",
        "    left: 60%;\n",
        "    width: 40%;\n",
        "    opacity: 0.35;\n",
        "}\n",
        "\n",
        "/* Yellow – slow depth layer */\n",
        ".matrix-yellow {\n",
        "    color: rgba(255, 220, 80, 0.45);\n",
        "    animation: matrixDown 22s linear infinite;\n",
        "    opacity: 0.25;\n",
        "}\n",
        "\n",
        "/* Green – LEFT blended rain */\n",
        ".matrix-green-left {\n",
        "    color: rgba(120, 255, 170, 0.55);\n",
        "    animation: matrixDown 16s linear infinite;\n",
        "    left: 0;\n",
        "    width: 50%;\n",
        "    opacity: 0.25;\n",
        "}\n",
        "\n",
        "/* Green – RIGHT blended rain */\n",
        ".matrix-green-right {\n",
        "    color: rgba(120, 255, 170, 0.45);\n",
        "    animation: matrixUp 19s linear infinite;\n",
        "    left: 50%;\n",
        "    width: 50%;\n",
        "    opacity: 0.22;\n",
        "}\n",
        "\n",
        "/* Animations */\n",
        "@keyframes matrixDown {\n",
        "    from { transform: translateY(-70%); }\n",
        "    to   { transform: translateY(70%); }\n",
        "}\n",
        "\n",
        "@keyframes matrixUp {\n",
        "    from { transform: translateY(70%); }\n",
        "    to   { transform: translateY(-70%); }\n",
        "}\n",
        "\n",
        "/* Streamlit UI above background */\n",
        "[data-testid=\"stAppViewContainer\"] {\n",
        "    position: relative;\n",
        "    z-index: 10;\n",
        "}\n",
        "\n",
        ".stApp {\n",
        "    background: #05070b;\n",
        "}\n",
        "\n",
        "[data-testid=\"stHeader\"],\n",
        "[data-testid=\"stToolbar\"] {\n",
        "    background: transparent !important;\n",
        "}\n",
        "\n",
        "</style>\n",
        "\n",
        "<div class=\"matrix-layer matrix-cyan\">\n",
        "010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101\n",
        "010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101\n",
        "</div>\n",
        "\n",
        "<div class=\"matrix-layer matrix-red\">\n",
        "101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010\n",
        "101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010\n",
        "</div>\n",
        "\n",
        "<div class=\"matrix-layer matrix-yellow\">\n",
        "010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101\n",
        "</div>\n",
        "\n",
        "<div class=\"matrix-layer matrix-green-left\">\n",
        "010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101\n",
        "010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101\n",
        "</div>\n",
        "\n",
        "<div class=\"matrix-layer matrix-green-right\">\n",
        "101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010\n",
        "101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "html, body, [class*=\"css\"] {\n",
        "    background-color: #0b0e14;\n",
        "    color: #e6e6e6;\n",
        "}\n",
        "\n",
        ".block-container {\n",
        "    padding-top: 2rem;\n",
        "    padding-left: 3rem;\n",
        "    padding-right: 3rem;\n",
        "}\n",
        "\n",
        "button[kind=\"primary\"] {\n",
        "    background: linear-gradient(90deg,#00f0ff,#ff0055);\n",
        "    border: none;\n",
        "    color: black;\n",
        "    font-weight: bold;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".stApp,\n",
        "[data-testid=\"stAppViewContainer\"],\n",
        "[data-testid=\"stHeader\"],\n",
        "[data-testid=\"stToolbar\"] {\n",
        "    background: transparent !important;\n",
        "}\n",
        "\n",
        ".block-container {\n",
        "    padding-top: 2rem;\n",
        "    padding-left: 3rem;\n",
        "    padding-right: 3rem;\n",
        "}\n",
        "\n",
        "button[kind=\"primary\"] {\n",
        "    background: linear-gradient(90deg,#00f0ff,#ff0055);\n",
        "    border: none;\n",
        "    color: black;\n",
        "    font-weight: bold;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Rajdhani:wght@700&display=swap');\n",
        "\n",
        ".cyberpunk-logo-wrap {\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "    margin-bottom: 35px;\n",
        "}\n",
        "\n",
        ".cyberpunk-logo {\n",
        "    font-family: 'Rajdhani', sans-serif;\n",
        "    font-size: 78px;\n",
        "    font-weight: 700;\n",
        "    letter-spacing: 6px;\n",
        "    color: #00f0ff;\n",
        "    display: inline-flex;\n",
        "}\n",
        "\n",
        ".cyberpunk-logo span {\n",
        "    position: relative;\n",
        "    display: inline-block;\n",
        "    animation: glitchMove 2.5s infinite ease-in-out;\n",
        "}\n",
        "\n",
        ".cyberpunk-logo span:nth-child(odd) { animation-delay: .15s; }\n",
        ".cyberpunk-logo span:nth-child(even) { animation-delay: .05s; }\n",
        "\n",
        ".cyberpunk-logo span::before,\n",
        ".cyberpunk-logo span::after {\n",
        "    content: attr(data-char);\n",
        "    position: absolute;\n",
        "    left: 0;\n",
        "    top: 0;\n",
        "    opacity: 0.8;\n",
        "}\n",
        "\n",
        ".cyberpunk-logo span::before {\n",
        "    color: #ff0055;\n",
        "    transform: translate(-2px, 0);\n",
        "    clip-path: polygon(0 0,100% 0,100% 45%,0 45%);\n",
        "}\n",
        "\n",
        ".cyberpunk-logo span::after {\n",
        "    color: #00f0ff;\n",
        "    transform: translate(2px, 0);\n",
        "    clip-path: polygon(0 55%,100% 55%,100% 100%,0 100%);\n",
        "}\n",
        "\n",
        "@keyframes glitchMove {\n",
        "    0%   { transform: translateY(0); }\n",
        "    20%  { transform: translateY(-1.5px); }\n",
        "    40%  { transform: translateY(1px); }\n",
        "    60%  { transform: translateY(-1px); }\n",
        "    80%  { transform: translateY(1.5px); }\n",
        "    100% { transform: translateY(0); }\n",
        "}\n",
        "\n",
        ".cyberpunk-subtitle {\n",
        "    text-align: center;\n",
        "    margin-top: 8px;\n",
        "    font-size: 13px;\n",
        "    letter-spacing: 4px;\n",
        "    color: #9aa0aa;\n",
        "}\n",
        "</style>\n",
        "\n",
        "<div class=\"cyberpunk-logo-wrap\">\n",
        "    <div class=\"cyberpunk-logo\">\n",
        "        <span data-char=\"C\">C</span>\n",
        "        <span data-char=\"Y\">Y</span>\n",
        "        <span data-char=\"B\">B</span>\n",
        "        <span data-char=\"E\">E</span>\n",
        "        <span data-char=\"R\">R</span>\n",
        "        <span data-char=\"P\">P</span>\n",
        "        <span data-char=\"U\">U</span>\n",
        "        <span data-char=\"N\">N</span>\n",
        "        <span data-char=\"K\">K</span>\n",
        "    </div>\n",
        "</div>\n",
        "\n",
        "<div class=\"cyberpunk-subtitle\">\n",
        "    IMAGE • RETRIEVAL • RAG\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "def panel(title, subtitle=None):\n",
        "    st.markdown(f\"\"\"\n",
        "    <div style=\"\n",
        "        border: 1px solid rgba(0,240,255,0.25);\n",
        "        border-left: 4px solid #00f0ff;\n",
        "        padding: 18px 22px;\n",
        "        margin-bottom: 22px;\n",
        "        background: linear-gradient(\n",
        "            145deg,\n",
        "            rgba(20,25,40,0.95),\n",
        "            rgba(10,14,20,0.95)\n",
        "        );\n",
        "    \">\n",
        "        <div style=\"\n",
        "            font-size: 13px;\n",
        "            letter-spacing: 2px;\n",
        "            color: #00f0ff;\n",
        "            margin-bottom: 6px;\n",
        "        \">\n",
        "            {title.upper()}\n",
        "        </div>\n",
        "        {\"<div style='font-size:12px;color:#888;margin-bottom:10px;'>\"+subtitle+\"</div>\" if subtitle else \"\"}\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def panel_end():\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "SRC_DIR = \"/content/cyberpunk_src\"\n",
        "if SRC_DIR not in sys.path:\n",
        "    sys.path.append(SRC_DIR)\n",
        "\n",
        "from extractors import generate_caption, image_embedding, text_embedding\n",
        "from rag import generate_answer\n",
        "from indexer import FaissIndex\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/cyberpunk_analyser\"\n",
        "INDEX_DIR = os.path.join(PROJECT_ROOT, \"indexes\")\n",
        "META_PATH = os.path.join(PROJECT_ROOT, \"metadata.csv\")\n",
        "IMAGES_DIR = os.path.join(PROJECT_ROOT, \"data\", \"images\")\n",
        "\n",
        "\n",
        "@st.cache_data(show_spinner=False)\n",
        "def load_metadata():\n",
        "    if os.path.exists(META_PATH):\n",
        "        return pd.read_csv(META_PATH)\n",
        "    return pd.DataFrame(columns=[\"id\",\"filename\",\"caption\",\"tags\",\"description\"])\n",
        "\n",
        "\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_indexes():\n",
        "    img_index = FaissIndex(1)\n",
        "    txt_index = FaissIndex(1)\n",
        "    img_index.load(os.path.join(INDEX_DIR, \"image_index\"))\n",
        "    txt_index.load(os.path.join(INDEX_DIR, \"text_index\"))\n",
        "    return img_index, txt_index\n",
        "\n",
        "meta = load_metadata()\n",
        "img_idx, txt_idx = load_indexes()\n",
        "\n",
        "\n",
        "st.sidebar.header(\"Input Image\")\n",
        "\n",
        "dataset_files = meta[\"filename\"].tolist() if not meta.empty else []\n",
        "choice = st.sidebar.selectbox(\n",
        "    \"Choose source\",\n",
        "    [\"Upload image\"] + dataset_files\n",
        ")\n",
        "\n",
        "\n",
        "uploaded = st.file_uploader(\n",
        "    \"Upload an image\",\n",
        "    type=[\"jpg\", \"jpeg\", \"png\"]\n",
        ")\n",
        "\n",
        "\n",
        "img = None\n",
        "image_path = None\n",
        "\n",
        "if uploaded is not None:\n",
        "    try:\n",
        "        img = Image.open(uploaded)\n",
        "        img.verify()\n",
        "        img = Image.open(uploaded)\n",
        "        image_path = \"/content/uploaded_image.png\"\n",
        "        with open(image_path, \"wb\") as f:\n",
        "            f.write(uploaded.getbuffer())\n",
        "    except Exception:\n",
        "        img = None\n",
        "        image_path = None\n",
        "\n",
        "elif choice != \"Upload image\":\n",
        "    candidate_path = os.path.join(IMAGES_DIR, choice)\n",
        "    if os.path.exists(candidate_path):\n",
        "        try:\n",
        "            img = Image.open(candidate_path)\n",
        "            img.verify()\n",
        "            img = Image.open(candidate_path)\n",
        "            image_path = candidate_path\n",
        "        except Exception:\n",
        "            img = None\n",
        "            image_path = None\n",
        "\n",
        "\n",
        "if img is not None and image_path is not None:\n",
        "\n",
        "    panel(\"Input Image\")\n",
        "    st.image(img, caption=\"Input image\", width=420)\n",
        "    panel_end()\n",
        "\n",
        "    panel(\"Generated Caption\", \"BLIP visual understanding\")\n",
        "    caption = generate_caption(image_path)\n",
        "    st.write(caption)\n",
        "    panel_end()\n",
        "\n",
        "    panel(\"Similar Images\", \"FAISS image retrieval\")\n",
        "    img_emb = image_embedding(image_path)\n",
        "    sim = img_idx.search(img_emb, top_k=6)\n",
        "\n",
        "    for sid, score in sim:\n",
        "        row = meta[meta[\"id\"] == sid]\n",
        "        if row.empty:\n",
        "            continue\n",
        "\n",
        "        filename = row.iloc[0][\"filename\"]\n",
        "        desc = row.iloc[0][\"description\"]\n",
        "        img_file = os.path.join(IMAGES_DIR, filename)\n",
        "\n",
        "        if pd.isna(desc) or str(desc).strip().lower() == \"nan\":\n",
        "            try:\n",
        "                desc = generate_caption(img_file)\n",
        "            except Exception:\n",
        "                desc = \"Description unavailable.\"\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        <div style=\"\n",
        "            margin-bottom: 18px;\n",
        "            padding: 14px;\n",
        "            background: rgba(255,255,255,0.03);\n",
        "            border-left: 3px solid #00f0ff;\n",
        "        \">\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        st.image(img_file, width=420)\n",
        "        st.markdown(\n",
        "            f\"<div style='font-size:12px;color:#9aa0aa;margin-top:6px;'>\"\n",
        "            f\"<b>{sid}</b> | similarity {score:.2f}\"\n",
        "            f\"</div>\",\n",
        "            unsafe_allow_html=True\n",
        "        )\n",
        "        st.markdown(f\"<div style='font-size:13px;margin-top:6px;'>{desc}</div>\",\n",
        "                    unsafe_allow_html=True)\n",
        "\n",
        "        st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    panel_end()\n",
        "\n",
        "    panel(\"Ask a Question\", \"RAG answer generation\")\n",
        "    question = st.text_input(\n",
        "        \"What technology or weapon is visible and how might it be used?\"\n",
        "    )\n",
        "\n",
        "    if st.button(\"Generate Answer\", type=\"primary\"):\n",
        "        answer = generate_answer([caption], question)\n",
        "        st.markdown(\"### Answer\")\n",
        "        st.write(answer)\n",
        "    panel_end()\n",
        "\n",
        "else:\n",
        "    panel(\"Waiting for Input\")\n",
        "    st.info(\"Upload an image or select one from the dataset.\")\n",
        "    panel_end()\n"
      ],
      "metadata": {
        "id": "zQh7o9QPn9HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"374oTb9lPDKZwvo39ovaUbWhgDR_872rZiByL7SCMkBxSTrDc\")\n"
      ],
      "metadata": {
        "id": "SCvj7MglExce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/streamlit_app.py\n"
      ],
      "metadata": {
        "id": "poGKMM26zUc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import nest_asyncio, subprocess, time\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(\"374oTb9lPDKZwvo39ovaUbWhgDR_872rZiByL7SCMkBxSTrDc\")\n",
        "\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "\n",
        "cmd = [\n",
        "    \"streamlit\", \"run\", \"/content/streamlit_app.py\",\n",
        "    \"--server.port\", \"8501\",\n",
        "    \"--server.headless\", \"true\",\n",
        "    \"--server.enableCORS\", \"false\"\n",
        "]\n",
        "subprocess.Popen(cmd)\n",
        "\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(8501, bind_tls=True)\n",
        "print(\"Streamlit public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "AmvLZ51xxAmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-vas4lGAxhaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
